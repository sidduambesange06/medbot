"""
Enhanced Medical Chatbot with Advanced Features
Production-Ready with OAuth, Chat History, Context-Aware RAG, and Session Management
"""

import os
import re
import requests
import logging
import json
import uuid
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
from functools import wraps
from dotenv import load_dotenv
from flask import Flask, render_template, request, jsonify, session, redirect, url_for, flash
from werkzeug.security import generate_password_hash, check_password_hash
from langchain_pinecone import PineconeVectorStore
from langchain_huggingface import HuggingFaceEmbeddings
from dataclasses import dataclass
import asyncio
from concurrent.futures import ThreadPoolExecutor
import numpy as np
from sentence_transformers import SentenceTransformer

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

# API Configuration
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GROQ_BASE_URL = "https://api.groq.com/openai/v1/chat/completions"

# Supabase Configuration
SUPABASE_URL = "https://vyzzvdimsuaeknpmyggt.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InZ5enp2ZGltc3VhZWtucG15Z2d0Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTM3NzM5NzQsImV4cCI6MjA2OTM0OTk3NH0.BPnPM0fdomDXm1qVwzPlvlW4sW-WazLByAF0X8m1u94"

if not PINECONE_API_KEY or not GROQ_API_KEY:
    raise ValueError("‚ùå Missing API keys in .env file")

# Chat Message and Context Classes
@dataclass
class ChatMessage:
    role: str
    message: str
    timestamp: datetime
    metadata: Dict = None
    relevance_score: float = 1.0

@dataclass
class ConversationSummary:
    summary: str
    key_topics: List[str]
    message_count: int
    timespan: str

# Enhanced Prompt Builder
class EnhancedPromptBuilder:
    def __init__(self, max_tokens: int = 4000):
        self.max_tokens = max_tokens
        
    def build_contextual_prompt(
        self,
        user_input: str,
        recent_history: List[ChatMessage],
        summaries: List[ConversationSummary] = None,
        semantic_matches: List[ChatMessage] = None,
        user_preferences: Dict = None
    ) -> str:
        """Build a comprehensive contextual prompt with multiple context sources."""
        
        prompt_parts = []
        
        # System prompt with user context
        system_prompt = self._build_system_prompt(user_preferences)
        prompt_parts.append(system_prompt)
        
        # Add conversation summaries for long-term context
        if summaries:
            summary_context = self._build_summary_context(summaries)
            prompt_parts.append(summary_context)
        
        # Add semantically relevant messages
        if semantic_matches:
            semantic_context = self._build_semantic_context(semantic_matches)
            prompt_parts.append(semantic_context)
        
        # Add recent conversation history
        if recent_history:
            recent_context = self._build_recent_context(recent_history)
            prompt_parts.append(recent_context)
        
        # Add current user input
        prompt_parts.append(f"\nUser: {user_input}\nAssistant:")
        
        # Combine and ensure token limit
        full_prompt = "\n".join(prompt_parts)
        return self._truncate_to_token_limit(full_prompt)
    
    def _build_system_prompt(self, user_preferences: Dict = None) -> str:
        base_prompt = """You are MedBot, an intelligent medical assistant with access to conversation history.

Key capabilities:
- Provide evidence-based medical information
- Remember previous conversations and build upon them
- Ask clarifying questions when context is missing
- Maintain conversation continuity across sessions"""

        if user_preferences:
            if user_preferences.get('communication_style'):
                base_prompt += f"\nCommunication style: {user_preferences['communication_style']}"
            if user_preferences.get('medical_background'):
                base_prompt += f"\nUser's medical background: {user_preferences['medical_background']}"
        
        return base_prompt
    
    def _build_summary_context(self, summaries: List[ConversationSummary]) -> str:
        if not summaries:
            return ""
        
        context = "\n=== Previous Conversation Summaries ==="
        for summary in summaries[:3]:  # Limit to 3 most relevant summaries
            context += f"\n[{summary.timespan}] {summary.summary}"
            if summary.key_topics:
                context += f" (Topics: {', '.join(summary.key_topics)})"
        
        return context + "\n"
    
    def _build_semantic_context(self, semantic_matches: List[ChatMessage]) -> str:
        if not semantic_matches:
            return ""
        
        context = "\n=== Relevant Previous Messages ==="
        for msg in semantic_matches[:5]:  # Limit to top 5 matches
            days_ago = (datetime.now() - msg.timestamp).days
            time_ref = f"{days_ago} days ago" if days_ago > 0 else "today"
            context += f"\n[{time_ref}] {msg.role.capitalize()}: {msg.message}"
        
        return context + "\n"
    
    def _build_recent_context(self, recent_history: List[ChatMessage]) -> str:
        if not recent_history:
            return ""
        
        context = "\n=== Recent Conversation ==="
        for msg in recent_history:
            context += f"\n{msg.role.capitalize()}: {msg.message}"
        
        return context
    
    def _truncate_to_token_limit(self, prompt: str) -> str:
        # Simple token estimation (4 chars ‚âà 1 token)
        estimated_tokens = len(prompt) // 4
        if estimated_tokens <= self.max_tokens:
            return prompt
        
        # Truncate from the middle, keeping system prompt and recent context
        lines = prompt.split('\n')
        system_lines = []
        recent_lines = []
        middle_lines = []
        
        in_recent = False
        for line in lines:
            if "Recent Conversation" in line:
                in_recent = True
            
            if not middle_lines and not in_recent:
                system_lines.append(line)
            elif in_recent:
                recent_lines.append(line)
            else:
                middle_lines.append(line)
        
        # Keep system and recent, truncate middle
        truncated = system_lines + ["...[previous context truncated]..."] + recent_lines[-10:]
        return '\n'.join(truncated)

# Enhanced Chat Service with Context Management
class EnhancedChatService:
    def __init__(self):
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        self.prompt_builder = EnhancedPromptBuilder()
        self.chat_history = {}  # In-memory storage for demo (replace with database)
        self.conversation_summaries = {}  # In-memory storage for demo
        self.user_preferences = {}  # In-memory storage for demo
    
    async def get_user_context_preferences(self, user_id: str) -> Dict:
        """Get user's context preferences or create defaults."""
        if user_id not in self.user_preferences:
            self.user_preferences[user_id] = {
                "max_context_messages": 10,
                "context_strategy": "mixed",
                "include_summaries": True,
                "auto_summarize_threshold": 50,
                "preferences": {}
            }
        return self.user_preferences[user_id]
    
    async def get_intelligent_context(
        self, 
        user_id: str, 
        current_input: str,
        session_id: str = None
    ) -> Tuple[List[ChatMessage], List[ConversationSummary], List[ChatMessage]]:
        """Get intelligent context using multiple strategies."""
        
        preferences = await self.get_user_context_preferences(user_id)
        strategy = preferences.get("context_strategy", "mixed")
        max_messages = preferences.get("max_context_messages", 10)
        
        # Get recent history
        recent_history = await self._get_recent_history(user_id, session_id, max_messages)
        
        # Get conversation summaries if enabled
        summaries = []
        if preferences.get("include_summaries", True):
            summaries = await self._get_relevant_summaries(user_id, current_input)
        
        # Get semantically similar messages
        semantic_matches = []
        if strategy in ["semantic", "mixed"]:
            semantic_matches = await self._get_semantic_matches(user_id, current_input)
        
        return recent_history, summaries, semantic_matches
    
    async def _get_recent_history(
        self, 
        user_id: str, 
        session_id: str = None, 
        limit: int = 10
    ) -> List[ChatMessage]:
        """Get recent chat history."""
        user_history = self.chat_history.get(user_id, [])
        
        if session_id:
            # Filter by session
            session_history = [msg for msg in user_history if msg.metadata and msg.metadata.get('session_id') == session_id]
            return session_history[-limit:] if session_history else []
        
        return user_history[-limit:] if user_history else []
    
    async def _get_semantic_matches(
        self, 
        user_id: str, 
        query_text: str, 
        limit: int = 5
    ) -> List[ChatMessage]:
        """Get semantically similar messages using simple similarity."""
        user_history = self.chat_history.get(user_id, [])
        
        if not user_history:
            return []
        
        # Simple keyword-based similarity for demo
        query_words = set(query_text.lower().split())
        similar_messages = []
        
        for msg in user_history:
            msg_words = set(msg.message.lower().split())
            similarity = len(query_words.intersection(msg_words)) / len(query_words.union(msg_words))
            
            if similarity > 0.1:  # Threshold for similarity
                msg.relevance_score = similarity
                similar_messages.append(msg)
        
        # Sort by relevance and return top matches
        similar_messages.sort(key=lambda x: x.relevance_score, reverse=True)
        return similar_messages[:limit]
    
    async def _get_relevant_summaries(
        self, 
        user_id: str, 
        query_text: str
    ) -> List[ConversationSummary]:
        """Get relevant conversation summaries."""
        user_summaries = self.conversation_summaries.get(user_id, [])
        return user_summaries[:3]  # Return top 3 summaries
    
    async def store_message_with_context(
        self,
        user_id: str,
        session_id: str,
        role: str,
        message: str,
        conversation_id: str = None,
        metadata: Dict = None
    ):
        """Store message with context."""
        if user_id not in self.chat_history:
            self.chat_history[user_id] = []
        
        chat_message = ChatMessage(
            role=role,
            message=message,
            timestamp=datetime.now(),
            metadata={
                'session_id': session_id,
                'conversation_id': conversation_id,
                **(metadata or {})
            }
        )
        
        self.chat_history[user_id].append(chat_message)
    
    async def should_summarize_conversation(self, user_id: str, session_id: str) -> bool:
        """Check if conversation should be summarized."""
        preferences = await self.get_user_context_preferences(user_id)
        threshold = preferences.get("auto_summarize_threshold", 50)
        
        user_history = self.chat_history.get(user_id, [])
        session_messages = [msg for msg in user_history if msg.metadata and msg.metadata.get('session_id') == session_id]
        
        return len(session_messages) >= threshold

# Medical Keywords for Query Classification
MEDICAL_KEYWORDS = [
    'disease', 'cancer', 'tumor', 'diabetes', 'hypertension', 'asthma', 'pneumonia',
    'tuberculosis', 'malaria', 'dengue', 'covid', 'flu', 'fever', 'infection',
    'hepatitis', 'cirrhosis', 'arthritis', 'osteoporosis', 'anemia', 'leukemia',
    'stroke', 'heart attack', 'angina', 'depression', 'anxiety', 'migraine',
    'alzheimer', 'parkinson', 'epilepsy', 'schizophrenia', 'bipolar',
    'pain', 'headache', 'nausea', 'vomiting', 'diarrhea', 'constipation',
    'cough', 'cold', 'sore throat', 'fatigue', 'weakness', 'dizziness',
    'shortness of breath', 'chest pain', 'abdominal pain', 'back pain',
    'joint pain', 'swelling', 'rash', 'itching', 'bleeding', 'bruising',
    'diagnosis', 'treatment', 'therapy', 'cure', 'medicine', 'medication',
    'drug', 'antibiotic', 'vaccine', 'surgery', 'operation', 'procedure',
    'examination', 'test', 'lab', 'x-ray', 'ct scan', 'mri', 'ultrasound',
    'biopsy', 'endoscopy', 'chemotherapy', 'radiotherapy', 'immunotherapy',
    'heart', 'lung', 'liver', 'kidney', 'brain', 'stomach', 'intestine',
    'blood', 'bone', 'muscle', 'nerve', 'skin', 'eye', 'ear', 'nose',
    'throat', 'respiratory', 'cardiovascular', 'gastrointestinal',
    'neurological', 'endocrine', 'immune', 'reproductive',
    'patient', 'doctor', 'physician', 'hospital', 'clinic', 'pharmacy',
    'prescription', 'dosage', 'side effect', 'allergy', 'symptom',
    'prevention', 'precaution', 'risk factor', 'complication',
    'what is', 'how to treat', 'cure for', 'symptoms of', 'causes of',
    'medicine for', 'drug for', 'prevention of', 'risk of'
]

class OptimizedMedicalRetriever:
    """Optimized medical knowledge retriever with production-ready responses"""
    
    def __init__(self):
        logger.info("üè• Initializing Medical Knowledge Retriever...")
        
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        
        self.vectorstore = PineconeVectorStore.from_existing_index(
            index_name="medical-chatbot-v2",
            embedding=self.embeddings
        )
        
        self.retriever = self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 6}
        )
        
        logger.info("‚úÖ Medical Knowledge Retriever ready")
    
    def is_medical_query(self, query: str) -> bool:
        """Enhanced medical query detection"""
        query_lower = query.lower()
        
        # Direct keyword matching
        for keyword in MEDICAL_KEYWORDS:
            if keyword in query_lower:
                return True
        
        # Medical question patterns
        medical_patterns = [
            r'\b(what|how|why|when|where)\s+.*\b(disease|symptom|treatment|medicine|drug|cure|diagnosis)\b',
            r'\b(symptoms?|causes?|treatment|cure|medicine|drug)\s+(of|for)\b',
            r'\b(how\s+to\s+(treat|cure|prevent|diagnose))\b',
            r'\b(side\s+effects?|dosage|prescription)\b',
            r'\b(medical|health|clinical|therapeutic)\b'
        ]
        
        for pattern in medical_patterns:
            if re.search(pattern, query_lower):
                return True
        
        return False
    
    def retrieve_medical_knowledge(self, query: str) -> Dict:
        """Retrieve and organize medical knowledge for production responses"""
        try:
            logger.info(f"üîç Searching medical textbooks for: {query}")
            
            docs = self.retriever.get_relevant_documents(query)
            
            if not docs:
                return {
                    'has_knowledge': False,
                    'content': '',
                    'sources': [],
                    'chunks_found': 0
                }
            
            medical_info = self._process_medical_content(docs, query)
            logger.info(f"‚úÖ Retrieved {medical_info['chunks_found']} relevant medical chunks")
            
            return medical_info
            
        except Exception as e:
            logger.error(f"‚ùå Error retrieving medical knowledge: {e}")
            return {
                'has_knowledge': False,
                'content': '',
                'sources': [],
                'chunks_found': 0,
                'error': str(e)
            }
    
    def _process_medical_content(self, docs, query: str) -> Dict:
        """Process medical chunks for optimized, production-ready content"""
        
        relevant_chunks = []
        sources = []
        unique_books = set()
        
        for doc in docs:
            if not hasattr(doc, 'page_content') or len(doc.page_content.strip()) < 100:
                continue
            
            content = doc.page_content.strip()
            metadata = doc.metadata
            
            book_name = metadata.get('filename', metadata.get('source', 'Medical Textbook'))
            if book_name.endswith('.pdf'):
                book_name = book_name.replace('.pdf', '').replace('_', ' ').title()
            
            page_num = metadata.get('page', 'N/A')
            
            chunk_info = {
                'content': content,
                'book_name': book_name,
                'page': page_num,
                'relevance': len([kw for kw in MEDICAL_KEYWORDS if kw in content.lower()])
            }
            
            relevant_chunks.append(chunk_info)
            
            source_key = f"{book_name}_{page_num}"
            if source_key not in [s['key'] for s in sources]:
                sources.append({
                    'book_name': book_name,
                    'page': page_num,
                    'key': source_key
                })
                unique_books.add(book_name)
        
        if not relevant_chunks:
            return {
                'has_knowledge': False,
                'content': '',
                'sources': [],
                'chunks_found': 0
            }
        
        sorted_chunks = sorted(relevant_chunks, key=lambda x: x['relevance'], reverse=True)
        optimized_content = self._create_optimized_content(sorted_chunks[:4], query)
        
        return {
            'has_knowledge': True,
            'content': optimized_content,
            'sources': sources[:5],
            'chunks_found': len(relevant_chunks),
            'unique_books': len(unique_books),
            'top_chunks': sorted_chunks[:3]
        }
    
    def _create_optimized_content(self, chunks: List[Dict], query: str) -> str:
        """Create optimized medical content with clear source attribution"""
        
        content_sections = []
        
        for chunk in chunks:
            sentences = chunk['content'].split('. ')
            relevant_sentences = []
            
            query_terms = query.lower().split()
            for sentence in sentences:
                sentence_lower = sentence.lower()
                relevance_score = sum(1 for term in query_terms if term in sentence_lower)
                if relevance_score > 0 or len(relevant_sentences) < 2:
                    relevant_sentences.append(sentence.strip())
                if len(relevant_sentences) >= 3:
                    break
            
            if relevant_sentences:
                section = '. '.join(relevant_sentences)
                if not section.endswith('.'):
                    section += '.'
                section += f" [{chunk['book_name']}, p.{chunk['page']}]"
                content_sections.append(section)
        
        return '\n\n'.join(content_sections)

class ProductionGroqInterface:
    """Production-optimized Groq API interface with refined prompts"""
    
    def __init__(self):
        self.available_models = [
            "llama3-70b-8192",
            "mixtral-8x7b-32768",
            "llama3-8b-8192"
        ]
    
    def call_groq_api(self, system_prompt: str, user_query: str, temperature: float = 0.1) -> Optional[str]:
        """Call Groq API with error handling"""
        
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }
        
        for model in self.available_models:
            try:
                payload = {
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_query}
                    ],
                    "model": model,
                    "max_tokens": 600,
                    "temperature": temperature,
                    "top_p": 0.9
                }
                
                response = requests.post(
                    GROQ_BASE_URL,
                    headers=headers,
                    json=payload,
                    timeout=30
                )
                
                if response.status_code == 200:
                    result = response.json()
                    if "choices" in result and result["choices"]:
                        content = result["choices"][0]["message"]["content"]
                        if content and len(content.strip()) > 10:
                            return content.strip()
                
                elif response.status_code == 429:
                    continue
                    
            except Exception as e:
                logger.warning(f"‚ùå {model} failed: {e}")
                continue
        
        return None
    
    def get_production_medical_prompt(self, medical_content: str, sources: List[Dict], query: str) -> str:
        """Production-optimized system prompt for medical queries"""
        
        return f"""You are a professional Medical AI Assistant providing evidence-based medical information from authoritative medical textbooks.

QUERY: {query}

MEDICAL TEXTBOOK CONTENT:
{medical_content}

RESPONSE GUIDELINES:
1. Provide a concise, professional medical response (150-300 words maximum)
2. Focus on directly answering the user's question
3. Use clear, accessible medical language
4. Organize information logically (definition ‚Üí symptoms ‚Üí causes ‚Üí treatment ‚Üí prevention)
5. Include only the most relevant and important information
6. Maintain professional medical tone
7. All citations are already included in the content - do not add additional ones

STRUCTURE YOUR RESPONSE:
- Brief, clear answer to the user's specific question
- Key medical facts organized logically
- Essential information only (avoid lengthy explanations)
- Professional medical terminology with brief explanations when needed

Remember: This is a production medical assistant - responses should be concise, authoritative, and directly helpful to healthcare queries.

Always end with: "‚ö†Ô∏è This information is from medical textbooks for educational purposes. Always consult healthcare professionals for medical advice."
"""
    
    def get_medical_fallback_prompt(self, query: str) -> str:
        """Optimized prompt when no medical textbook knowledge is found"""
        return f"""You are a Medical AI Assistant. The user asked: "{query}"

No specific information was found in the medical textbook database for this query.

Provide a brief, professional response that:
1. Acknowledges the lack of specific textbook information
2. Gives general medical guidance (2-3 sentences maximum)
3. Strongly recommends consulting healthcare professionals
4. Keeps the response concise and helpful

Format: Brief explanation + professional recommendation + medical disclaimer.

Always end with: "‚ö†Ô∏è For accurate medical information, please consult qualified healthcare professionals."
"""
    
    def get_general_system_prompt(self) -> str:
        """System prompt for non-medical queries"""
        return """You are a helpful AI assistant. This question is not medical-related, so provide a clear, concise, and helpful response using your general knowledge. Keep the response focused and informative without unnecessary elaboration."""

class ProductionMedicalChatbot:
    """Production-ready Medical Chatbot with enhanced context awareness"""
    
    def __init__(self):
        self.medical_retriever = OptimizedMedicalRetriever()
        self.groq_interface = ProductionGroqInterface()
        self.chat_service = EnhancedChatService()
        logger.info("üè• Production Medical Chatbot initialized")
    
    async def process_query_with_context(self, query: str, user_context: Dict = None, session_id: str = None) -> str:
        """Main query processing with enhanced context awareness"""
        
        logger.info(f"üìù Processing: {query}")
        
        # Add user context to logging if available
        if user_context:
            logger.info(f"üë§ User: {user_context.get('email', 'Anonymous')} ({user_context.get('role', 'user')})")
        
        user_id = user_context.get('id', 'anonymous') if user_context else 'anonymous'
        
        # Get intelligent context
        recent_history, summaries, semantic_matches = await self.chat_service.get_intelligent_context(
            user_id, query, session_id
        )
        
        # Get user preferences for prompt building
        preferences = await self.chat_service.get_user_context_preferences(user_id)
        
        is_medical = self.medical_retriever.is_medical_query(query)
        
        if is_medical:
            logger.info("üè• Medical query detected")
            
            medical_knowledge = self.medical_retriever.retrieve_medical_knowledge(query)
            
            if medical_knowledge['has_knowledge']:
                logger.info(f"‚úÖ Found medical knowledge from {medical_knowledge['unique_books']} textbooks")
                
                # Build enhanced prompt with context
                enhanced_query = self.chat_service.prompt_builder.build_contextual_prompt(
                    user_input=query,
                    recent_history=recent_history,
                    summaries=summaries,
                    semantic_matches=semantic_matches,
                    user_preferences=preferences.get("preferences", {})
                )
                
                system_prompt = self.groq_interface.get_production_medical_prompt(
                    medical_knowledge['content'],
                    medical_knowledge['sources'],
                    enhanced_query
                )
                
                response = self.groq_interface.call_groq_api(system_prompt, enhanced_query, temperature=0.1)
                
                if response:
                    if medical_knowledge['sources']:
                        source_info = "\n\nüìö **Sources:** " + ", ".join([
                            f"{s['book_name']} (p.{s['page']})" 
                            for s in medical_knowledge['sources'][:3]
                        ])
                        response += source_info
                else:
                    response = self._get_fallback_response(query, medical_knowledge)
            
            else:
                logger.info("‚ùå No specific medical textbook knowledge found")
                
                system_prompt = self.groq_interface.get_medical_fallback_prompt(query)
                response = self.groq_interface.call_groq_api(system_prompt, query, temperature=0.2)
                
                if not response:
                    response = f"""I couldn't find specific information about "{query}" in the medical textbook database.

For accurate medical information about this topic, I recommend:
‚Ä¢ Consulting with healthcare professionals
‚Ä¢ Referring to current medical literature
‚Ä¢ Contacting medical specialists if needed

‚ö†Ô∏è For accurate medical information, please consult qualified healthcare professionals."""
        
        else:
            logger.info("üí¨ General query detected")
            
            # Build context for general queries too
            if recent_history or semantic_matches:
                enhanced_query = self.chat_service.prompt_builder.build_contextual_prompt(
                    user_input=query,
                    recent_history=recent_history,
                    summaries=summaries,
                    semantic_matches=semantic_matches,
                    user_preferences=preferences.get("preferences", {})
                )
            else:
                enhanced_query = query
            
            system_prompt = self.groq_interface.get_general_system_prompt()
            response = self.groq_interface.call_groq_api(system_prompt, enhanced_query, temperature=0.7)
            
            if not response:
                response = "I'm here to help! Could you please provide more details or rephrase your question?"
        
        # Store message with context
        await self.chat_service.store_message_with_context(
            user_id, session_id or str(uuid.uuid4()), "user", query
        )
        await self.chat_service.store_message_with_context(
            user_id, session_id or str(uuid.uuid4()), "assistant", response
        )
        
        return response
    
    def _get_fallback_response(self, query: str, medical_knowledge: Dict) -> str:
        """Generate fallback response when API fails but we have medical sources"""
        
        sources_text = ""
        if medical_knowledge['sources']:
            sources_text = "\n\nüìö **Relevant Sources Found:**\n" + "\n".join([
                f"‚Ä¢ {source['book_name']}, Page {source['page']}"
                for source in medical_knowledge['sources'][:3]
            ])
        
        return f"""I found relevant medical information in the textbook database but encountered a technical issue generating the response.

Please refer to the medical textbook sources below for information about "{query}".
{sources_text}

‚ö†Ô∏è This information is from medical textbooks for educational purposes. Always consult healthcare professionals for medical advice."""

# Authentication Decorators and Utilities
def auth_required(f):
    """Decorator to require authentication for routes"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        # Check for authenticated session
        if 'user' not in session and not is_guest_session():
            return redirect(url_for('login'))
        return f(*args, **kwargs)
    return decorated_function

def is_guest_session():
    """Check if current session is a valid guest session"""
    return 'guest_session' in session and session.get('guest_session', False)

def get_user_context():
    """Get current user context for logging and personalization"""
    if 'user' in session:
        return {
            'id': session['user'].get('id'),
            'email': session['user'].get('email'),
            'name': session['user'].get('name'),
            'role': session['user'].get('role', 'user'),
            'avatar': session['user'].get('avatar'),
            'is_guest': False
        }
    elif is_guest_session():
        return {
            'id': session.get('guest_id', 'guest_unknown'),
            'email': 'guest@medai.pro',
            'name': 'Guest User',
            'role': 'guest',
            'avatar': None,
            'is_guest': True
        }
    else:
        return None

# Flask Application Setup
app = Flask(__name__)
app.secret_key = os.getenv('SECRET_KEY', 'medai-pro-secret-key-change-in-production')
app.config['SESSION_PERMANENT'] = False
app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(days=7)

# Initialize chatbot
chatbot = ProductionMedicalChatbot()

# Authentication Routes
@app.route("/")
def index():
    """Landing page - redirect based on auth status"""
    if 'user' in session or is_guest_session():
        return redirect(url_for('chat'))
    return redirect(url_for('login'))

@app.route("/login")
def login():
    """OAuth login page - serves Oauth.html from templates"""
    # If already authenticated, redirect to chat
    if 'user' in session or is_guest_session():
        return redirect(url_for('chat'))
    
    return render_template("Oauth.html")

# FIXED ROUTE: OAuth Callback Handler (POST)
@app.route('/auth/callback', methods=['POST'])
def auth_callback():
    """Process OAuth callback from Supabase frontend - ENHANCED VERSION"""
    try:
        auth_data = request.get_json()
        
        if not auth_data:
            logger.error("‚ùå No auth data received in callback")
            return jsonify({"success": False, "error": "No authentication data received"}), 400
        
        logger.info(f"üîÑ Processing auth callback: {auth_data.get('type', 'unknown')}")
        
        # Handle both OAuth callback and session restore
        if 'user' in auth_data and auth_data['user']:
            user_data = auth_data['user']
            session_data = auth_data.get('session', {})
            
            # Extract user information
            user_email = user_data.get('email')
            user_name = user_data.get('user_metadata', {}).get('full_name') or user_data.get('user_metadata', {}).get('name')
            if not user_name and user_email:
                user_name = user_email.split('@')[0].title()
            
            # Store user session in Flask session
            session['user'] = {
                'id': user_data.get('id'),
                'email': user_email,
                'name': user_name,
                'avatar': user_data.get('user_metadata', {}).get('avatar_url'),
                'role': 'authenticated',
                'provider': user_data.get('app_metadata', {}).get('provider', 'unknown'),
                'created_at': user_data.get('created_at'),
                'access_token': session_data.get('access_token'),
                'refresh_token': session_data.get('refresh_token'),
                'authenticated_at': datetime.now().isoformat()
            }
            
            # Mark session as permanent for longer persistence
            session.permanent = True
            
            # Clear any guest session
            session.pop('guest_session', None)
            session.pop('guest_id', None)
            
            logger.info(f"‚úÖ User authenticated successfully: {user_email} via {session['user']['provider']}")
            
            return jsonify({
                "success": True,
                "user": {
                    "email": user_email,
                    "name": user_name,
                    "provider": session['user']['provider']
                },
                "message": "Authentication successful",
                "redirect_url": "/chat"
            })
        
        # Handle error cases
        elif 'error' in auth_data:
            error_msg = auth_data.get('error_description', auth_data['error'])
            logger.error(f"‚ùå Auth error: {error_msg}")
            return jsonify({
                "success": False, 
                "error": error_msg
            }), 400
        
        else:
            logger.error("‚ùå Invalid auth data structure")
            logger.debug(f"Received data: {auth_data}")
            return jsonify({
                "success": False, 
                "error": "Invalid authentication data structure"
            }), 400
        
    except Exception as e:
        logger.error(f"‚ùå Auth callback error: {e}")
        import traceback
        logger.error(f"Full traceback: {traceback.format_exc()}")
        return jsonify({
            "success": False, 
            "error": "Authentication processing failed"
        }), 500

# ENHANCED ROUTE: Guest Authentication (POST)
@app.route('/auth/guest', methods=['POST']) 
def guest_auth():
    """Create guest session - ENHANCED VERSION"""
    try:
        guest_id = f"guest_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{os.urandom(4).hex()}"
        
        # Create guest session
        session['guest_session'] = True
        session['guest_id'] = guest_id
        session['guest_created'] = datetime.now().isoformat()
        session.permanent = False  # Guest sessions are temporary
        
        logger.info(f"üé≠ Guest session created: {guest_id}")
        
        return jsonify({
            "success": True,
            "guest_id": guest_id,
            "message": "Guest session created successfully",
            "redirect_url": "/chat"
        })
        
    except Exception as e:
        logger.error(f"‚ùå Guest auth error: {e}")
        return jsonify({
            "success": False, 
            "error": "Failed to create guest session"
        }), 500

# ENHANCED ROUTE: Chat Interface with Context
@app.route('/chat')
def chat():
    """Serve enhanced chat.html with proper session authentication"""
    # Get user context
    user_context = get_user_context()
    
    if not user_context:
        # No authentication - redirect to login
        flash("Please sign in to access the chat interface.", "warning")
        logger.warning("üö´ Unauthorized chat access attempt")
        return redirect(url_for('login'))
    
    # User is authenticated (either OAuth or guest)
    logger.info(f"üí¨ Chat access granted to: {user_context['email']} ({user_context['role']})")
    
    # Pass user context to template for personalization
    return render_template("chat.html", user=user_context)

@app.route("/logout")
def logout():
    """Logout and clear session"""
    user_info = get_user_context()
    if user_info:
        logger.info(f"üëã User logged out: {user_info['email']}")
    
    session.clear()
    flash("You have been logged out successfully.", "info")
    return redirect(url_for('login'))

# ENHANCED Chat API Routes with Context
@app.route("/get", methods=["POST"])
@auth_required
def chat_api():
    """Enhanced Chat API endpoint with context awareness"""
    try:
        query = request.form.get("msg", "").strip()
        
        if not query:
            return jsonify({"answer": "Please enter a message."}), 400
        
        # Get user context for personalized responses
        user_context = get_user_context()
        session_id = session.get('current_session_id', str(uuid.uuid4()))
        
        # Store session ID for continuity
        session['current_session_id'] = session_id
        
        # Log query with user context
        if user_context:
            logger.info(f"üí¨ Query from {user_context['email']} ({user_context['role']}): {query[:50]}...")
        
        # Process query through enhanced medical chatbot with context
        import asyncio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        response = loop.run_until_complete(
            chatbot.process_query_with_context(query, user_context, session_id)
        )
        
        # Add personalized footer for authenticated users
        if user_context and not user_context['is_guest']:
            response += f"\n\n*Personalized response for {user_context['name']}*"
        
        return jsonify({
            "answer": response,
            "session_id": session_id,
            "context_info": {
                "user_type": "authenticated" if not user_context['is_guest'] else "guest",
                "has_history": True,
                "personalized": not user_context['is_guest']
            }
        })
    
    except Exception as e:
        logger.error(f"‚ùå Error in enhanced chat endpoint: {e}")
        error_response = """I'm experiencing technical difficulties. Please try again.

‚ö†Ô∏è For medical concerns, always consult qualified healthcare professionals."""
        return jsonify({"answer": error_response}), 500

# ENHANCED User Management Routes
@app.route("/chat/history/<user_id>")
@auth_required
def get_chat_history(user_id):
    """Get paginated chat history with enhanced context"""
    try:
        user_context = get_user_context()
        
        # Security check - users can only access their own history
        if user_context['id'] != user_id and user_context['role'] != 'admin':
            return jsonify({"error": "Unauthorized access"}), 403
        
        session_id = request.args.get('session_id')
        limit = int(request.args.get('limit', 50))
        offset = int(request.args.get('offset', 0))
        
        # Get chat history from enhanced chat service
        import asyncio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        recent_history = loop.run_until_complete(
            chatbot.chat_service._get_recent_history(user_id, session_id, limit)
        )
        
        # Convert to serializable format
        history_data = []
        for msg in recent_history[offset:offset+limit]:
            history_data.append({
                "role": msg.role,
                "message": msg.message,
                "timestamp": msg.timestamp.isoformat(),
                "metadata": msg.metadata
            })
        
        return jsonify({
            "messages": history_data,
            "count": len(history_data),
            "total_available": len(recent_history),
            "user_context": user_context
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error getting chat history: {e}")
        return jsonify({"error": "Failed to retrieve chat history"}), 500

@app.route("/chat/sessions/<user_id>")
@auth_required
def get_user_sessions(user_id):
    """Get all chat sessions for a user with enhanced metadata"""
    try:
        user_context = get_user_context()
        
        # Security check
        if user_context['id'] != user_id and user_context['role'] != 'admin':
            return jsonify({"error": "Unauthorized access"}), 403
        
        # Get user's chat history and group by sessions
        user_history = chatbot.chat_service.chat_history.get(user_id, [])
        
        sessions = {}
        for msg in user_history:
            session_id = msg.metadata.get('session_id', 'default') if msg.metadata else 'default'
            
            if session_id not in sessions:
                sessions[session_id] = {
                    'session_id': session_id,
                    'start_time': msg.timestamp,
                    'end_time': msg.timestamp,
                    'message_count': 0,
                    'last_activity': msg.timestamp
                }
            
            sessions[session_id]['end_time'] = max(sessions[session_id]['end_time'], msg.timestamp)
            sessions[session_id]['message_count'] += 1
            sessions[session_id]['last_activity'] = msg.timestamp
        
        # Convert to list and sort by last activity
        session_list = list(sessions.values())
        session_list.sort(key=lambda x: x['last_activity'], reverse=True)
        
        # Convert timestamps to ISO format
        for session in session_list:
            session['start_time'] = session['start_time'].isoformat()
            session['end_time'] = session['end_time'].isoformat()
            session['last_activity'] = session['last_activity'].isoformat()
        
        return jsonify({
            "sessions": session_list,
            "total_sessions": len(session_list),
            "user_context": user_context
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error getting user sessions: {e}")
        return jsonify({"error": "Failed to retrieve user sessions"}), 500

@app.route("/chat/preferences/<user_id>", methods=['GET', 'POST'])
@auth_required
def user_context_preferences(user_id):
    """Get/Update user's context preferences"""
    try:
        user_context = get_user_context()
        
        # Security check
        if user_context['id'] != user_id and user_context['role'] != 'admin':
            return jsonify({"error": "Unauthorized access"}), 403
        
        import asyncio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        if request.method == 'GET':
            preferences = loop.run_until_complete(
                chatbot.chat_service.get_user_context_preferences(user_id)
            )
            return jsonify({"preferences": preferences})
        
        elif request.method == 'POST':
            new_preferences = request.get_json()
            
            # Update preferences
            current_prefs = loop.run_until_complete(
                chatbot.chat_service.get_user_context_preferences(user_id)
            )
            current_prefs.update(new_preferences)
            
            chatbot.chat_service.user_preferences[user_id] = current_prefs
            
            return jsonify({
                "message": "Preferences updated successfully",
                "preferences": current_prefs
            })
        
    except Exception as e:
        logger.error(f"‚ùå Error handling preferences: {e}")
        return jsonify({"error": "Failed to handle preferences"}), 500

@app.route("/profile")
@auth_required
def profile():
    """Enhanced user profile page with context info"""
    user_context = get_user_context()
    
    if user_context['is_guest']:
        flash("Guest users cannot access profile. Please sign in with an account.", "warning")
        return redirect(url_for('chat'))
    
    # Get additional user stats
    user_id = user_context['id']
    user_history = chatbot.chat_service.chat_history.get(user_id, [])
    
    return jsonify({
        "user": user_context,
        "session_info": {
            "login_time": session.get('authenticated_at', 'Unknown'),
            "session_type": "authenticated",
            "provider": user_context.get('provider', 'Unknown')
        },
        "usage_stats": {
            "total_messages": len(user_history),
            "sessions": len(set(msg.metadata.get('session_id', 'default') 
                              for msg in user_history if msg.metadata)),
            "first_interaction": user_history[0].timestamp.isoformat() if user_history else None,
            "last_interaction": user_history[-1].timestamp.isoformat() if user_history else None
        }
    })

@app.route("/session/info")
@auth_required
def session_info():
    """Get enhanced current session information"""
    user_context = get_user_context()
    
    return jsonify({
        "authenticated": user_context is not None,
        "user": user_context,
        "session_type": "guest" if user_context and user_context['is_guest'] else "authenticated",
        "current_session_id": session.get('current_session_id'),
        "features": {
            "unlimited_queries": not (user_context and user_context['is_guest']),
            "chat_history": not (user_context and user_context['is_guest']),
            "personalized_responses": not (user_context and user_context['is_guest']),
            "advanced_features": not (user_context and user_context['is_guest']),
            "context_awareness": True,
            "conversation_summaries": not (user_context and user_context['is_guest']),
            "semantic_search": True,
            "multi_session_memory": not (user_context and user_context['is_guest'])
        }
    })

# System Routes with Enhanced Information
@app.route("/health")
def health_check():
    """Enhanced system health check with full feature status"""
    try:
        # Test medical query processing
        test_query = "diabetes symptoms"
        is_medical = chatbot.medical_retriever.is_medical_query(test_query)
        
        # Test Pinecone connection
        try:
            test_knowledge = chatbot.medical_retriever.retrieve_medical_knowledge("diabetes")
            pinecone_status = f"‚úÖ Working - {test_knowledge['chunks_found']} chunks found"
        except Exception as e:
            pinecone_status = f"‚ùå Error: {str(e)[:50]}..."
        
        # Check current session
        user_context = get_user_context()
        auth_status = "‚úÖ Authenticated" if user_context else "‚ùå Not authenticated"
        
        return jsonify({
            "status": "healthy",
            "mode": "ENHANCED Production Medical Chatbot with Context-Aware RAG",
            "version": "2.0.0-ENHANCED",
            "authentication": {
                "system": "‚úÖ Supabase OAuth + Guest Sessions + Enhanced Security",
                "current_session": auth_status,
                "user_context": user_context,
                "session_keys": list(session.keys()) if session else []
            },
            "enhanced_features": {
                "context_aware_rag": "‚úÖ Multi-strategy context retrieval",
                "conversation_memory": "‚úÖ Session-based chat history",
                "semantic_matching": "‚úÖ Previous conversation relevance",
                "conversation_summaries": "‚úÖ Long-term memory management",
                "user_preferences": "‚úÖ Personalized context strategies",
                "session_management": "‚úÖ Multi-session conversation tracking",
                "medical_query_detection": "‚úÖ Enhanced keyword + pattern matching",
                "medical_source": "‚úÖ Pinecone vector database with medical textbooks",
                "response_optimization": "‚úÖ Concise, professional medical responses",
                "citations": "‚úÖ Book names + page numbers",
                "fallback_handling": "‚úÖ LLM guidance when textbook info unavailable",
                "oauth_authentication": "‚úÖ Google, GitHub OAuth via Supabase",
                "guest_sessions": "‚úÖ Anonymous access with limitations",
                "user_personalization": "‚úÖ Context-aware responses",
                "parallel_processing": "‚úÖ Optimized performance"
            },
            "medical_classification": f"‚úÖ Test query '{test_query}' classified as: {'Medical' if is_medical else 'General'}",
            "pinecone_connection": pinecone_status,
            "context_features": {
                "recent_history": "‚úÖ Last 10 messages per session",
                "semantic_matches": "‚úÖ Top 5 relevant previous messages",
                "conversation_summaries": "‚úÖ Key topics and themes",
                "user_preferences": "‚úÖ Customizable context strategies",
                "token_optimization": "‚úÖ Smart prompt truncation"
            },
            "response_settings": {
                "max_tokens": 600,
                "temperature": 0.1,
                "retrieval_k": 6,
                "max_sources_displayed": 3,
                "context_window": "4000 tokens",
                "max_context_messages": 10
            },
            "supabase_config": {
                "url": SUPABASE_URL,
                "key_configured": bool(SUPABASE_KEY)
            },
            "performance_optimizations": [
                "‚úÖ Parallel PDF processing",
                "‚úÖ Batch embedding generation",
                "‚úÖ Optimized vector search",
                "‚úÖ Smart context selection",
                "‚úÖ Token-aware prompt building",
                "‚úÖ Async processing support"
            ]
        })
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500

# Error Handlers
@app.errorhandler(404)
def not_found(error):
    return render_template('Oauth.html'), 404

@app.errorhandler(500)
def internal_error(error):
    logger.error(f"‚ùå Internal server error: {error}")
    return jsonify({"error": "Internal server error"}), 500

@app.route("/about")
def about():
    """Enhanced about page with comprehensive feature list"""
    return jsonify({
        "version": "2.0.0-ENHANCED",
        "status": "Production Ready with Context-Aware RAG",
        "core_features": [
            "‚úÖ ENHANCED Context-Aware RAG System",
            "‚úÖ Multi-Strategy Context Retrieval (Recent, Semantic, Summaries)",
            "‚úÖ Session-Based Conversation Memory",
            "‚úÖ User Preference Management",
            "‚úÖ OAuth Authentication (Google, GitHub via Supabase)",
            "‚úÖ Guest Sessions with Limited Access",
            "‚úÖ Personalized Medical Responses",
            "‚úÖ Advanced Session Management & Security"
        ],
        "medical_features": [
            "‚úÖ Evidence-based answers from medical textbooks",
            "‚úÖ Enhanced medical query classification",
            "‚úÖ Professional medical disclaimers",
            "‚úÖ Clean citations with book names & pages",
            "‚úÖ Optimized response length (150-300 words)",
            "‚úÖ Fallback handling for unknown queries",
            "‚úÖ Context-aware medical consultations"
        ],
        "technical_features": [
            "‚úÖ Pinecone Vector Database Integration",
            "‚úÖ HuggingFace Embeddings (MiniLM-L6-v2)",
            "‚úÖ Groq LLM API with Multiple Models",
            "‚úÖ Async Processing Support",
            "‚úÖ Parallel PDF Processing",
            "‚úÖ Smart Token Management",
            "‚úÖ Production-Ready Error Handling"
        ],
        "context_system": {
            "recent_history": "Maintains conversation flow within sessions",
            "semantic_matching": "Finds relevant previous conversations",
            "conversation_summaries": "Long-term memory for extended interactions",
            "user_preferences": "Customizable context strategies (recent/semantic/mixed)",
            "intelligent_selection": "Optimal context for each query type"
        }
    })

@app.route("/privacy")
def privacy():
    """Privacy policy page"""
    return jsonify({"message": "Privacy policy endpoint - implement as needed"})

@app.route("/terms")
def terms():
    """Terms of service page"""
    return jsonify({"message": "Terms of service endpoint - implement as needed"})

# Development/Debug Routes
@app.route("/debug/session")
def debug_session():
    """Debug enhanced session information - REMOVE IN PRODUCTION"""
    if app.debug:
        user_context = get_user_context()
        user_id = user_context.get('id', 'anonymous') if user_context else 'anonymous'
        
        return jsonify({
            "session_data": dict(session),
            "user_context": user_context,
            "is_guest": is_guest_session(),
            "session_keys": list(session.keys()),
            "chat_history_count": len(chatbot.chat_service.chat_history.get(user_id, [])),
            "user_preferences": chatbot.chat_service.user_preferences.get(user_id, {}),
            "conversation_summaries": len(chatbot.chat_service.conversation_summaries.get(user_id, []))
        })
    else:
        return jsonify({"error": "Debug mode disabled"}), 403

@app.route("/debug/context/<user_id>")
def debug_context(user_id):
    """Debug user context information - REMOVE IN PRODUCTION"""
    if app.debug:
        import asyncio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        # Get sample context
        test_query = "diabetes symptoms"
        recent_history, summaries, semantic_matches = loop.run_until_complete(
            chatbot.chat_service.get_intelligent_context(user_id, test_query)
        )
        
        return jsonify({
            "user_id": user_id,
            "test_query": test_query,
            "recent_history": [
                {
                    "role": msg.role,
                    "message": msg.message[:100] + "..." if len(msg.message) > 100 else msg.message,
                    "timestamp": msg.timestamp.isoformat()
                } for msg in recent_history
            ],
            "summaries": [
                {
                    "summary": summary.summary[:100] + "..." if len(summary.summary) > 100 else summary.summary,
                    "topics": summary.key_topics,
                    "timespan": summary.timespan
                } for summary in summaries
            ],
            "semantic_matches": [
                {
                    "role": msg.role,
                    "message": msg.message[:100] + "..." if len(msg.message) > 100 else msg.message,
                    "relevance_score": msg.relevance_score
                } for msg in semantic_matches
            ]
        })
    else:
        return jsonify({"error": "Debug mode disabled"}), 403

if __name__ == "__main__":
    print("üöÄ Starting ENHANCED Production Medical Chatbot")
    print("=" * 80)
    print("üè• ENHANCED FEATURES:")
    print("‚úÖ Context-Aware RAG System with Multi-Strategy Retrieval")
    print("‚úÖ Session-Based Conversation Memory & History")
    print("‚úÖ Semantic Matching for Previous Conversations")
    print("‚úÖ User Preference Management & Personalization")
    print("‚úÖ OAuth + Guest Authentication with Enhanced Security")
    print("‚úÖ Conversation Summaries for Long-Term Memory")
    print("‚úÖ Advanced Session Management & Tracking")
    print("‚úÖ Production-Ready Performance Optimizations")
    print("=" * 80)
    print("üè• MEDICAL FEATURES:")
    print("‚úÖ Evidence-based Medical Information from Textbooks")
    print("‚úÖ Enhanced Medical Query Classification")
    print("‚úÖ Context-Aware Medical Consultations")
    print("‚úÖ Professional Citations & Disclaimers")
    print("‚úÖ Optimized Response Generation")
    print("=" * 80)
    print("üîê Authentication System: Enhanced Supabase OAuth + Guest Sessions")
    print("üåê Available at: http://localhost:8080")
    print("üîë Login page: http://localhost:8080/login")
    print("üí¨ Enhanced Chat: http://localhost:8080/chat")
    print("üîß Health check: http://localhost:8080/health")
    print("üìä Debug session: http://localhost:8080/debug/session")
    print("üß† Debug context: http://localhost:8080/debug/context/<user_id>")
    print("=" * 80)
    print("\nüìã ENHANCED API ENDPOINTS:")
    print("‚úÖ POST /auth/callback - OAuth processing with enhanced security")
    print("‚úÖ POST /auth/guest - Guest session creation")
    print("‚úÖ GET /chat - Enhanced chat interface with context")
    print("‚úÖ POST /get - Context-aware chat API")
    print("‚úÖ GET /chat/history/<user_id> - Paginated chat history")
    print("‚úÖ GET /chat/sessions/<user_id> - Session management")
    print("‚úÖ GET/POST /chat/preferences/<user_id> - User preferences")
    print("=" * 80)
    print("\nüéØ CONTEXT SYSTEM FEATURES:")
    print("‚Ä¢ Recent History: Last 10 messages per session")
    print("‚Ä¢ Semantic Matching: Top 5 relevant previous messages")
    print("‚Ä¢ Conversation Summaries: Key topics and themes")
    print("‚Ä¢ User Preferences: Customizable context strategies")
    print("‚Ä¢ Token Optimization: Smart prompt truncation")
    print("=" * 80)
    
    app.run(host="0.0.0.0", port=8080, debug=True, use_reloader=True)